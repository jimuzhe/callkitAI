import 'dart:async';
import 'dart:io';
import 'dart:math';
import 'dart:typed_data';

import 'package:audio_session/audio_session.dart';
import 'package:flutter/foundation.dart';
import 'package:flutter/services.dart';
import 'package:just_audio/just_audio.dart';
import 'package:path_provider/path_provider.dart';
import 'package:record/record.dart';
import 'package:synchronized/synchronized.dart';

import '../audio/pcm_stream_player.dart';
import '../utils/wav_validator.dart';
import '../utils/audio_format_detector.dart';
import 'opus_decoder_service.dart';
import 'pcm_stream_service.dart';

enum _AudioMode { playback, voiceChat }

class AudioService {
  static final AudioService instance = AudioService._init();

  final AudioRecorder _recorder = AudioRecorder();
  
  // ç‹¬ç«‹çš„çŸ­éŸ³æ•ˆæ’­æ”¾å™¨ï¼ˆä¸å¹²æ‰°ä¸»æ’­æ”¾å™¨ï¼‰
  final AudioPlayer _sfxPlayer = AudioPlayer();
  DateTime? _lastSfxAt;
  final _playerLock = Lock();
  final _streamLock = Lock();
  final _sessionLock = Lock();

  // Player and state
  final AudioPlayer _player = AudioPlayer();
  final AudioPlayer _streamPlayer = AudioPlayer(); // ä¿®å¤ï¼šä¸ºæµå¼æ’­æ”¾ä½¿ç”¨ç‹¬ç«‹çš„æ’­æ”¾å™¨
  StreamSubscription<PlayerState>? _playerStateSub;

  // Recording stream controller (forward raw PCM frames)
  StreamController<List<int>>? _audioStreamController;

  // Current audio mode (playback by default)
  _AudioMode _currentAudioMode = _AudioMode.playback;

  PCMStreamPlayer? _pcmStreamPlayer;

  bool _isRecording = false;
  bool _isPlaying = false;
  bool _keepAlive = false;
  bool _streamingSessionActive =
      false; // we switched to playback for streaming and are holding it
  bool _restoreToVoiceChatAfterStream =
      false; // restore session after stream completes
  bool _resumeRecordingAfterStream = false;
  
  // é™ä½è°ƒè¯•æ—¥å¿—é¢‘ç‡ï¼Œé¿å…ä¸»çº¿ç¨‹é˜»å¡å¯¼è‡´çš„æŠ–åŠ¨
  int _processLogCounter = 0;

  AudioService._init();

  bool get isRecording => _isRecording;
  bool get isPlaying => _isPlaying;
  Stream<List<int>>? get audioStream => _audioStreamController?.stream;

  bool get hasAudioStreamListener =>
      _audioStreamController?.hasListener ?? false;

  bool get isVoiceChatMode => _currentAudioMode == _AudioMode.voiceChat;

  Future<void> initialize() async {
    // ä¸åœ¨åˆå§‹åŒ–æ—¶é…ç½®éŸ³é¢‘ä¼šè¯ï¼Œç­‰å¾…å®é™…ä½¿ç”¨æ—¶å†é…ç½®
    // è¿™æ ·å¯ä»¥é¿å…ä¸åç»­çš„è¯­éŸ³èŠå¤©æ¨¡å¼é…ç½®å†²çª
    debugPrint('ğŸµ AudioService åˆå§‹åŒ–ï¼Œç­‰å¾…å®é™…ä½¿ç”¨æ—¶é…ç½®éŸ³é¢‘ä¼šè¯');

    _ensurePcmStreamPlayer();

    // åˆå§‹åŒ– Opus è§£ç å™¨ï¼ˆAIé€šè¯å¿…éœ€ï¼‰
    try {
      await OpusDecoderService.instance.initialize();
      debugPrint('âœ… OpusDecoderService åˆå§‹åŒ–æˆåŠŸ');
    } catch (e) {
      debugPrint('âŒ OpusDecoderService åˆå§‹åŒ–å¤±è´¥: $e');
    }

    // Web å¹³å°æš‚ä¸ä½¿ç”¨åŸç”Ÿ record æ’ä»¶
    if (kIsWeb) {
      debugPrint('âš ï¸ Web å¹³å°ï¼šåŸç”Ÿå½•éŸ³ä¸å—æ”¯æŒï¼Œè¯·åœ¨ iOS/Android è®¾å¤‡è¿è¡Œä»¥ä½¿ç”¨éº¦å…‹é£åŠŸèƒ½');
      return;
    }

    // æ£€æŸ¥å½•éŸ³æƒé™
    if (!await _recorder.hasPermission()) {
      debugPrint('âš ï¸ æ²¡æœ‰å½•éŸ³æƒé™');
      return;
    }
  }

  // --- Streaming (AI voice) ---
  void _ensurePcmStreamPlayer() {
    if (_pcmStreamPlayer != null) return;
    // ä¿®å¤ï¼šä½¿ç”¨ç‹¬ç«‹çš„æµå¼æ’­æ”¾å™¨ï¼Œé¿å…ä¸æ™®é€šæ’­æ”¾å™¨å†²çª
    _pcmStreamPlayer = PCMStreamPlayer(
      player: _streamPlayer,
      onPlaybackStateChanged: (playing) {
        _isPlaying = playing;
      },
      onPlaybackCompleted: () async {
        if (_streamingSessionActive) {
          final needRestore = _restoreToVoiceChatAfterStream;
          final shouldResumeRecording = _resumeRecordingAfterStream;
          _streamingSessionActive = false;
          _restoreToVoiceChatAfterStream = false;
          _resumeRecordingAfterStream = false;
          if (needRestore) {
            try {
              await ensureVoiceChatMode();
            } catch (e) {
              debugPrint('âš ï¸ æ¢å¤è¯­éŸ³èŠå¤©æ¨¡å¼å¤±è´¥: $e');
            }
            if (shouldResumeRecording) {
              try {
                await startRecording();
                debugPrint('ğŸ™ï¸ å®æ—¶é€šè¯ï¼šæ¢å¤éº¦å…‹é£å½•éŸ³');
              } catch (e) {
                debugPrint('âš ï¸ å®æ—¶é€šè¯ï¼šæ¢å¤å½•éŸ³å¤±è´¥: $e');
              }
            }
          }
        }
      },
    );
  }

  Future<void> _ensureStreamPlaylist() async {
    _ensurePcmStreamPlayer();
    await _pcmStreamPlayer!.ensureInitialized();

    // æå‰æ¿€æ´»éŸ³é¢‘ä¼šè¯ï¼Œå‡å°‘é¦–æ¬¡æ’­æ”¾å»¶æ—¶
    try {
      final session = await AudioSession.instance;
      await session.setActive(true);
      debugPrint('âœ… æå‰æ¿€æ´»éŸ³é¢‘ä¼šè¯æˆåŠŸ');
    } catch (e) {
      debugPrint('âš ï¸ æå‰æ¿€æ´»éŸ³é¢‘ä¼šè¯å¤±è´¥: $e');
    }
  }

  // ä½¿ç”¨ PCMStreamService å®ç°çœŸæ­£çš„æµå¼æ’­æ”¾
  Future<void> streamWavFragment(Uint8List wavBytes) async {
    debugPrint('ğŸµ streamWavFragment: æ¥æ”¶åˆ°æ•°æ®é•¿åº¦ ${wavBytes.length}');

    if (wavBytes.isEmpty) {
      debugPrint('âš ï¸ ç©ºéŸ³é¢‘æ•°æ®ï¼Œè·³è¿‡');
      return;
    }

    try {
      if (!_streamingSessionActive) {
        debugPrint('ğŸ”Š åˆå§‹åŒ–PCMæµæ’­æ”¾ä¼šè¯');
        
        if (_keepAlive) {
          await stopBackgroundKeepAlive();
        }
        
        final inVoiceChatMode = _currentAudioMode == _AudioMode.voiceChat;
        debugPrint('ğŸ¤ å½“å‰éŸ³é¢‘æ¨¡å¼: ${inVoiceChatMode ? "è¯­éŸ³èŠå¤©" : "æ’­æ”¾"}');
        
        _streamingSessionActive = true;
      }

      // ä½¿ç”¨ PCMStreamService ç›´æ¥æ’­æ”¾ï¼ˆè‡ªåŠ¨å¤„ç†WAVå¤´ï¼‰
      await PCMStreamService.instance.feedWAV(wavBytes);
      debugPrint('âœ… PCMæ•°æ®å·²å–‚å…¥æµå¼æ’­æ”¾å™¨');
    } catch (e, stackTrace) {
      debugPrint('âŒ streamWavFragment å¼‚å¸¸: $e');
      debugPrint('ğŸ“ å †æ ˆä¿¡æ¯: $stackTrace');
    }
  }

  /// åˆ·æ–°æµå¼æ’­æ”¾ç¼“å†²ï¼ˆPCMæµä¸éœ€è¦æ˜¾å¼ flushï¼‰
  Future<void> flushStreaming() async {
    debugPrint('ğŸ§¹ flushStreaming: PCMæµå¼æ’­æ”¾è‡ªåŠ¨å¤„ç†');
    // PCMStreamService è‡ªåŠ¨ç®¡ç†ç¼“å†²ï¼Œä¸éœ€è¦æ˜¾å¼ flush
  }

  /// ç«‹å³åœæ­¢å½“å‰PCMæµå¼æ’­æ”¾å¹¶æ¸…ç©ºé˜Ÿåˆ—
  Future<void> stopStreamingAndClear() async {
    try {
      debugPrint('ğŸš¦ åœæ­¢PCMæµå¼æ’­æ”¾');
      await PCMStreamService.instance.stopStreaming();
    } catch (e) {
      debugPrint('stopStreamingAndClear failed: $e');
    } finally {
      _streamingSessionActive = false;
      _restoreToVoiceChatAfterStream = false;
      _resumeRecordingAfterStream = false;
    }
  }
  
  /// æ£€æŸ¥éŸ³é¢‘æ’­æ”¾æ˜¯å¦å¡æ­»å¹¶å°è¯•æ¢å¤
  Future<void> checkAndRecoverPlayback() async {
    try {
      final pcmService = PCMStreamService.instance;
      
      // å¦‚æœæ’­æ”¾å™¨æ˜¾ç¤ºæ­£åœ¨æ’­æ”¾ä½†å®é™…ä¸Šæ²¡æœ‰å£°éŸ³è¾“å‡º
      if (pcmService.isPlaying && _streamingSessionActive) {
        debugPrint('ğŸ¤– æ£€æŸ¥æ’­æ”¾çŠ¶æ€...');
        
        // å¦‚æœæ£€æµ‹åˆ°å¯èƒ½çš„å¡æ­»æƒ…å†µï¼Œå°è¯•é‡å¯
        // è¿™é‡Œå¯ä»¥æ·»åŠ æ›´ç²¾ç»†çš„æ£€æµ‹é€»è¾‘
        debugPrint('ğŸ”„ å°è¯•é‡ç½®éŸ³é¢‘æ’­æ”¾çŠ¶æ€');
        await stopStreamingAndClear();
        await Future.delayed(const Duration(milliseconds: 300));
        // è‡ªåŠ¨é‡å¯å°†ç”±åç»­æ•°æ®è§¦å‘
      }
    } catch (e) {
      debugPrint('âš ï¸ æ£€æŸ¥å’Œæ¢å¤æ’­æ”¾å¤±è´¥: $e');
    }
  }

  /// å–‚å…¥PCMæ•°æ®åˆ°æµå¼æ’­æ”¾å™¨ï¼ˆä¼˜åŒ–ç‰ˆ - å‡å°‘æ—¥å¿—ï¼‰
  Future<void> _feedPcmToStream(Uint8List pcmData) async {
    try {
      if (!_streamingSessionActive) {
        debugPrint('ğŸ”Š åˆå§‹åŒ–PCMæµæ’­æ”¾ä¼šè¯');
        
        if (_keepAlive) {
          await stopBackgroundKeepAlive();
        }
        
        final inVoiceChatMode = _currentAudioMode == _AudioMode.voiceChat;
        debugPrint('ğŸ¤ å½“å‰éŸ³é¢‘æ¨¡å¼: ${inVoiceChatMode ? "è¯­éŸ³èŠå¤©" : "æ’­æ”¾"}');
        
        _streamingSessionActive = true;
      }

      // ç›´æ¥å–‚å…¥PCMæ•°æ®ï¼Œä¸æ·»åŠ WAVå¤´éƒ¨
      await PCMStreamService.instance.feedPCM(pcmData);
      
      // ä¼˜åŒ–ï¼šå‡å°‘æ—¥å¿—è¾“å‡ºï¼ˆæ¯100æ¬¡è¾“å‡ºä¸€æ¬¡ï¼‰
      if (_processLogCounter % 100 == 0) {
        debugPrint('âœ… PCMæ•°æ®å·²å–‚å…¥æµå¼æ’­æ”¾å™¨ (${pcmData.length} bytes)');
      }
    } catch (e, stackTrace) {
      debugPrint('âŒ _feedPcmToStream å¼‚å¸¸: $e');
      debugPrint('ğŸ“ å †æ ˆä¿¡æ¯: $stackTrace');
    }
  }

  /// ç»Ÿä¸€çš„éŸ³é¢‘å¤„ç†å…¥å£ - é›†æˆäº†è§£ç é€»è¾‘
  ///
  /// è‡ªåŠ¨è¯†åˆ«éŸ³é¢‘æ ¼å¼å¹¶å¤„ç†ï¼š
  /// - Opus: è§£ç ä¸º PCM åæµå¼æ’­æ”¾
  /// - WAV: æå–PCMæ•°æ®åæµå¼æ’­æ”¾
  /// - å…¶ä»–æ ¼å¼: å°è¯•ç›´æ¥æ’­æ”¾
  Future<void> processAudioData(
    Uint8List audioData, {
    String? declaredFormat,
  }) async {
    if (audioData.isEmpty) {
      debugPrint('âš ï¸ æ”¶åˆ°ç©ºéŸ³é¢‘æ•°æ®ï¼Œè·³è¿‡');
      return;
    }

    try {
      // è‡ªåŠ¨æ£€æµ‹æ ¼å¼
      final detectedFormat = AudioFormatDetector.detectFormat(audioData);
      final effectiveFormat = declaredFormat ?? detectedFormat.name;

      _processLogCounter++;
      if (_processLogCounter % 15 == 0) {
        debugPrint(
          'ğŸµ å¤„ç†éŸ³é¢‘æ•°æ®: é•¿åº¦=${audioData.length}, å£°æ˜æ ¼å¼=$declaredFormat, æ£€æµ‹æ ¼å¼=${detectedFormat.name}',
        );
      }

      // å¤„ç† Opus æ ¼å¼ï¼ˆéœ€è¦è§£ç ï¼‰
      if (_isOpusFormat(detectedFormat, declaredFormat)) {
        await _processOpusAudio(audioData);
        return;
      }

      // å¤„ç† WAV æ ¼å¼ï¼ˆç›´æ¥æµå¼æ’­æ”¾ï¼‰
      if (_isWavFormat(audioData)) {
        await streamWavFragment(audioData);
        return;
      }

      // å…¶ä»–æ ¼å¼å°è¯•ç›´æ¥æ’­æ”¾
      final ext = _mapFormatToExtension(effectiveFormat);
      if (ext != null) {
        debugPrint('ğŸµ å°è¯•ç›´æ¥æ’­æ”¾æ ¼å¼: $ext');
        await playAudioFromBytes(audioData, ext: ext);
        return;
      }

      // å…œåº•ï¼šå°è¯•ä½œä¸º WAV æ’­æ”¾
      debugPrint('âš ï¸ æœªçŸ¥æ ¼å¼ï¼Œå°è¯•ä½œä¸º WAV æ’­æ”¾');
      await streamWavFragment(audioData);
    } catch (e, stack) {
      debugPrint('âŒ å¤„ç†éŸ³é¢‘æ•°æ®å¤±è´¥: $e');
      debugPrint('ğŸ“ $stack');
    }
  }

  /// å¤„ç† Opus ç¼–ç çš„éŸ³é¢‘ï¼ˆä¼˜åŒ–ç‰ˆ - å‡å°‘å»¶è¿Ÿï¼‰
  Future<void> _processOpusAudio(Uint8List opusData) async {
    try {
      // ç¡®ä¿ Opus è§£ç å™¨å·²åˆå§‹åŒ–
      if (!OpusDecoderService.instance.isInitialized) {
        debugPrint('âš ï¸ Opus è§£ç å™¨æœªåˆå§‹åŒ–ï¼Œæ­£åœ¨åˆå§‹åŒ–...');
        await OpusDecoderService.instance.initialize();
      }

      // ä¼˜åŒ–ï¼šç›´æ¥è§£ç ï¼Œä¸ä½¿ç”¨ computeï¼ˆisolate ä¼šå¢åŠ å»¶è¿Ÿï¼‰
      // Opus è§£ç éå¸¸å¿«ï¼Œä¸ä¼šé˜»å¡ä¸»çº¿ç¨‹
      final pcmData = await OpusDecoderService.instance.decode(opusData);

      if (pcmData.isEmpty) {
        debugPrint('âš ï¸ Opus è§£ç è¿”å›ç©ºæ•°æ®');
        return;
      }

      // å‡å°‘æ—¥å¿—è¾“å‡ºï¼ˆæ¯20æ¬¡è¾“å‡ºä¸€æ¬¡ï¼‰
      _processLogCounter++;
      if (_processLogCounter % 20 == 0) {
        debugPrint(
          'âœ… Opus è§£ç : ${opusData.length} -> ${pcmData.length} bytes PCM',
        );
      }

      // ç›´æ¥å–‚å…¥PCMæ•°æ®åˆ°æµå¼æ’­æ”¾å™¨
      await _feedPcmToStream(pcmData);
    } catch (e) {
      debugPrint('âŒ Opus è§£ç å¤±è´¥: $e');
    }
  }

  /// åˆ¤æ–­æ˜¯å¦ä¸º Opus æ ¼å¼
  bool _isOpusFormat(AudioFormat detected, String? declaredFormat) {
    if (declaredFormat != null) {
      final lower = declaredFormat.toLowerCase();
      return lower.contains('opus') || lower == 'ogg';
    }
    return detected == AudioFormat.rawOpus || detected == AudioFormat.oggOpus;
  }

  /// åˆ¤æ–­æ˜¯å¦ä¸º WAV æ ¼å¼
  bool _isWavFormat(Uint8List data) {
    if (data.length < 12) return false;
    return data[0] == 0x52 && // R
        data[1] == 0x49 && // I
        data[2] == 0x46 && // F
        data[3] == 0x46 && // F
        data[8] == 0x57 && // W
        data[9] == 0x41 && // A
        data[10] == 0x56 && // V
        data[11] == 0x45; // E
  }

  /// æ˜ å°„æ ¼å¼åˆ°æ–‡ä»¶æ‰©å±•å
  String? _mapFormatToExtension(String? format) {
    if (format == null) return null;

    final lower = format.toLowerCase();
    switch (lower) {
      case 'opus':
      case 'ogg':
      case 'oggopus':
        return 'ogg';
      case 'wav':
      case 'pcm':
        return 'wav';
      case 'mp3':
      case 'mpeg':
        return 'mp3';
      case 'aac':
      case 'm4a':
        return 'aac';
      default:
        return null;
    }
  }

  Future<void> startRecording() async {
    try {
      if (_isRecording) return;

      if (kIsWeb) {
        debugPrint('âš ï¸ startRecording: Web å¹³å°ä¸æ”¯æŒ record.startStream()');
        throw UnsupportedError('Recording is not supported on web');
      }

      _audioStreamController = StreamController<List<int>>.broadcast();

      final tempDir = await getTemporaryDirectory();
      final String fileExt = 'pcm';
      final path =
          '${tempDir.path}/audio_${DateTime.now().millisecondsSinceEpoch}.$fileExt';

      final config = RecordConfig(
        encoder: AudioEncoder.pcm16bits,
        sampleRate: 16000,
        numChannels: 1,
        echoCancel: true,
        noiseSuppress: true,
      );

      // å¼€å§‹å½•éŸ³å¹¶è·å–æµ
      final stream = await _recorder.startStream(config);

      _isRecording = true;

      // è½¬å‘éŸ³é¢‘æµ
      stream.listen(
        (data) {
          _audioStreamController?.add(data);
        },
        onError: (error) {
          debugPrint('å½•éŸ³æµé”™è¯¯: $error');
        },
        onDone: () {
          debugPrint('å½•éŸ³æµç»“æŸ');
        },
      );

      debugPrint('å¼€å§‹å½•éŸ³: $path');
    } catch (e) {
      debugPrint('å¼€å§‹å½•éŸ³å¤±è´¥: $e');
      _isRecording = false;
    }
  }

  // åå°ä¿æ´»ï¼šä»¥é™éŸ³å¾ªç¯æ–¹å¼å ç”¨éŸ³é¢‘ä¼šè¯ï¼Œé¿å… App åœ¨åå°è¢«æŒ‚èµ·
  Future<void> startBackgroundKeepAlive() async {
    try {
      if (_keepAlive) return;

      await _ensureSessionForBackground();

      await _player.stop();
      // ä¸´æ—¶ä½¿ç”¨ä¸€ä¸ªæå°çš„éŸ³é¢‘æ•°æ®è¿›è¡Œä¿æ´»ï¼Œé¿å…æ–‡ä»¶ä¾èµ–
      final minimalAudioData = _createMinimalAudioData();
      final tempDir = await getTemporaryDirectory();
      final tempFilePath =
          '${tempDir.path}/keepalive_${DateTime.now().millisecondsSinceEpoch}.wav';
      final file = File(tempFilePath);
      await file.writeAsBytes(minimalAudioData, flush: true);

      await _player.setFilePath(tempFilePath);
      await _player.setLoopMode(LoopMode.one);
      final keepAliveVolume = Platform.isIOS ? 0.01 : 0.0;
      await _player.setVolume(keepAliveVolume);
      await _playWithRetry();
      _keepAlive = true;
      debugPrint('å¯åŠ¨åå°ä¿æ´»ï¼ˆé™éŸ³å¾ªç¯ï¼‰');
    } catch (e) {
      debugPrint('å¯åŠ¨åå°ä¿æ´»å¤±è´¥: $e');
      _keepAlive = false;
    }
  }

  Future<void> stopBackgroundKeepAlive() async {
    try {
      if (!_keepAlive) return;
      await _player.stop();
      await _player.setLoopMode(LoopMode.off);
      await _player.setVolume(1.0);
      await _playerStateSub?.cancel();
      _playerStateSub = null;
      _keepAlive = false;
      debugPrint('åœæ­¢åå°ä¿æ´»');
    } catch (e) {
      debugPrint('åœæ­¢åå°ä¿æ´»å¤±è´¥: $e');
    }
  }

  bool get isBackgroundKeepingAlive => _keepAlive;

  Future<void> ensureBackgroundKeepAlive() async {
    if (_keepAlive) return;
    await startBackgroundKeepAlive();
  }

  Future<void> disableBackgroundKeepAlive() async {
    if (!_keepAlive) return;
    await stopBackgroundKeepAlive();
  }

  Future<void> _ensureSessionForBackground() async {
    try {
      final session = await AudioSession.instance;
      await session.setActive(true);
    } catch (e) {
      debugPrint('é‡æ–°æ¿€æ´»éŸ³é¢‘ä¼šè¯å¤±è´¥: $e');
    }
  }

  Future<void> _configurePlaybackSession() async {
    await _sessionLock.synchronized(() async {
      try {
        final session = await AudioSession.instance;
        // ä¿®å¤ï¼šç›´æ¥é‡æ–°é…ç½®ï¼Œä¸å…ˆ deactivateï¼Œé¿å… iOS é”™è¯¯
        await session.configure(const AudioSessionConfiguration.music());
        await session.setActive(true);
        _currentAudioMode = _AudioMode.playback;
        debugPrint('âœ… éŸ³é¢‘ä¼šè¯å·²é…ç½®ä¸ºæ’­æ”¾æ¨¡å¼');
      } catch (e) {
        debugPrint('âš ï¸ é…ç½®æ’­æ”¾ä¼šè¯å¤±è´¥: $e');
        // å³ä½¿å¤±è´¥ä¹Ÿæ›´æ–°çŠ¶æ€ï¼Œå¹¶å°è¯•æ¿€æ´»
        _currentAudioMode = _AudioMode.playback;
        try {
          final session = await AudioSession.instance;
          await session.setActive(true);
        } catch (_) {}
      }
    });
  }

  Future<void> _configureVoiceChatSession() async {
    await _sessionLock.synchronized(() async {
      try {
        final session = await AudioSession.instance;
        // ä¿®å¤ï¼šç›´æ¥é‡æ–°é…ç½®ï¼Œä¸å…ˆ deactivate
        await session.configure(
          AudioSessionConfiguration(
            avAudioSessionCategory: AVAudioSessionCategory.playAndRecord,
            avAudioSessionCategoryOptions:
                AVAudioSessionCategoryOptions.defaultToSpeaker |
                AVAudioSessionCategoryOptions.allowBluetooth,
            avAudioSessionMode: AVAudioSessionMode.voiceChat,
            androidAudioAttributes: const AndroidAudioAttributes(
              contentType: AndroidAudioContentType.speech,
              usage: AndroidAudioUsage.voiceCommunication,
            ),
          ),
        );
        await session.setActive(true);
        _currentAudioMode = _AudioMode.voiceChat;
        debugPrint('ğŸ”Š éŸ³é¢‘ä¼šè¯å·²é…ç½®ä¸ºè¯­éŸ³èŠå¤©æ¨¡å¼ï¼ˆæ”¯æŒå¤–æ”¾/è“ç‰™ï¼‰');
      } catch (e) {
        debugPrint('âš ï¸ é…ç½®è¯­éŸ³èŠå¤©ä¼šè¯å¤±è´¥: $e');
        _currentAudioMode = _AudioMode.voiceChat;
        try {
          final session = await AudioSession.instance;
          await session.setActive(true);
        } catch (_) {}
      }
    });
  }

  Future<T> _withPlaybackMode<T>(Future<T> Function() action) async {
    final bool shouldRestoreVoiceChat =
        _currentAudioMode == _AudioMode.voiceChat;

    // ä¿®å¤ï¼šä¸åœæ­¢å½•éŸ³ï¼Œè¯­éŸ³èŠå¤©æ¨¡å¼æ”¯æŒåŒæ—¶å½•éŸ³å’Œæ’­æ”¾
    // åªéœ€ç¡®ä¿éŸ³é¢‘ä¼šè¯æ¿€æ´»
    debugPrint(
      'ğŸ§­ æ’­æ”¾å‰æ¨¡å¼: ${_currentAudioMode.name}, isRecording: $_isRecording',
    );

    // å¦‚æœå·²ç»åœ¨è¯­éŸ³èŠå¤©æ¨¡å¼ï¼Œåªéœ€ç¡®ä¿ä¼šè¯æ¿€æ´»
    if (shouldRestoreVoiceChat) {
      await _sessionLock.synchronized(() async {
        try {
          final session = await AudioSession.instance;
          await session.setActive(true);
          debugPrint('ğŸ”Š ä¿æŒè¯­éŸ³èŠå¤©æ¨¡å¼ï¼Œç¡®ä¿ä¼šè¯æ¿€æ´»');
        } catch (e) {
          debugPrint('âš ï¸ æ¿€æ´»è¯­éŸ³èŠå¤©ä¼šè¯å¤±è´¥: $e');
        }
      });
    } else {
      // å¦‚æœä¸åœ¨è¯­éŸ³èŠå¤©æ¨¡å¼ï¼Œéœ€è¦é…ç½®æ’­æ”¾æ¨¡å¼
      await _sessionLock.synchronized(() async {
        try {
          await _configurePlaybackSession();
          debugPrint('ğŸµ åˆ‡æ¢åˆ°æ’­æ”¾æ¨¡å¼');
        } catch (e) {
          debugPrint('âš ï¸ é…ç½®æ’­æ”¾æ¨¡å¼å¤±è´¥: $e');
        }
      });
    }

    try {
      return await action();
    } finally {
      debugPrint('ğŸµ æ’­æ”¾æ“ä½œå®Œæˆï¼Œä¿æŒå½“å‰éŸ³é¢‘ä¼šè¯æ¨¡å¼');
    }
  }

  Future<void> _playWithRetry({int retries = 2}) async {
    int attempt = 0;
    while (true) {
      try {
        await _player.play();
        return;
      } catch (e) {
        attempt++;
        if (attempt > retries) rethrow;
        await Future.delayed(const Duration(milliseconds: 500));
        await _ensureSessionForBackground();
      }
    }
  }

  Future<void> stopRecording() async {
    try {
      if (!_isRecording) return;

      await _recorder.stop();
      await _audioStreamController?.close();
      _audioStreamController = null;
      _isRecording = false;

      debugPrint('åœæ­¢å½•éŸ³');
    } catch (e) {
      debugPrint('åœæ­¢å½•éŸ³å¤±è´¥: $e');
    }
  }

  Future<void> playAudioFromBytes(List<int> audioData, {String? ext}) async {
    await _playerLock.synchronized(() async {
      await _withPlaybackMode(() async {
        try {
          await _player.stop();

          if (_keepAlive) {
            await stopBackgroundKeepAlive();
          }

          final chosenExt = ext ?? _guessExt(audioData);
          final audioBytes = Uint8List.fromList(audioData);

          // å¦‚æœæ˜¯ WAV æ ¼å¼ï¼ŒéªŒè¯æ–‡ä»¶å¤´
          if (chosenExt == 'wav') {
            debugPrint('ğŸ” éªŒè¯ WAV æ–‡ä»¶æ ¼å¼...');
            WavValidator.printWavHeader(audioBytes);
            final isValid = WavValidator.validateWav(audioBytes);
            final hasData = WavValidator.hasValidSamples(audioBytes);

            if (!isValid) {
              debugPrint('âŒ WAV æ–‡ä»¶æ ¼å¼æ— æ•ˆï¼Œå°è¯•æ’­æ”¾å¯èƒ½å¤±è´¥');
            }
            if (!hasData) {
              debugPrint('âš ï¸ WAV æ–‡ä»¶ä¼¼ä¹æ˜¯é™éŸ³æ•°æ®');
            }
          }

          // ä½¿ç”¨å†…å­˜æµæ’­æ”¾ï¼ˆæ‰€æœ‰å¹³å°é€šç”¨ï¼Œä¸æŒä¹…åŒ–æ–‡ä»¶ï¼‰
          final source = _buildInMemoryAudioSource(
            audioBytes,
            contentType: _contentTypeForExt(chosenExt),
          );

          await _player.setAudioSource(source);
          await _player.setVolume(1.0);
          _isPlaying = true;

          _player.play();

          await _playerStateSub?.cancel();
          _playerStateSub = _player.playerStateStream.listen((state) {
            debugPrint('ğŸµ æ’­æ”¾çŠ¶æ€: ${state.processingState}');
            if (state.processingState == ProcessingState.completed) {
              _isPlaying = false;
            }
          });

          debugPrint('âœ… å†…å­˜æµæ’­æ”¾ ${chosenExt.toUpperCase()}');
        } catch (e) {
          debugPrint('âŒ æ’­æ”¾éŸ³é¢‘å¤±è´¥: $e');
          _isPlaying = false;
          rethrow;
        }
      });
    });
  }

  String _guessExt(List<int> bytes) {
    if (bytes.length >= 12) {
      if (bytes[0] == 0x52 &&
          bytes[1] == 0x49 &&
          bytes[2] == 0x46 &&
          bytes[3] == 0x46 &&
          bytes[8] == 0x57 &&
          bytes[9] == 0x41 &&
          bytes[10] == 0x56 &&
          bytes[11] == 0x45) {
        return 'wav';
      }
      if (bytes[0] == 0x4F &&
          bytes[1] == 0x67 &&
          bytes[2] == 0x67 &&
          bytes[3] == 0x53) {
        return 'ogg';
      }
      if (bytes[0] == 0x49 && bytes[1] == 0x44 && bytes[2] == 0x33) {
        return 'mp3';
      }
      if (bytes[0] == 0x63 &&
          bytes[1] == 0x61 &&
          bytes[2] == 0x66 &&
          bytes[3] == 0x66) {
        return 'caf';
      }
    }
    if (bytes.length >= 2 && bytes[0] == 0xFF && (bytes[1] & 0xF0) == 0xF0) {
      return 'aac';
    }
    return 'wav';
  }

  String _contentTypeForExt(String ext) {
    switch (ext.toLowerCase()) {
      case 'ogg':
        return 'audio/ogg';
      case 'mp3':
        return 'audio/mpeg';
      case 'aac':
        return 'audio/aac';
      case 'caf':
        return 'audio/x-caf';
      case 'wav':
      default:
        return 'audio/wav';
    }
  }

  AudioSource _buildInMemoryAudioSource(
    Uint8List buffer, {
    required String contentType,
  }) {
    return _BytesAudioSource(buffer, contentType: contentType);
  }

  /// æ’­æ”¾çŸ­ä¿ƒçš„ UI éŸ³æ•ˆï¼ˆå¸¦æœ€å°è§¦å‘é—´éš”ï¼Œé¿å…æ»šåŠ¨æ—¶è¿‡åº¦è§¦å‘ï¼‰
  Future<void> playUiEffectFromAsset(
    String assetPath, {
    double volume = 0.3,
    int minIntervalMs = 120,
  }) async {
    try {
      final now = DateTime.now();
      if (_lastSfxAt != null &&
          now.difference(_lastSfxAt!).inMilliseconds < minIntervalMs) {
        return; // èŠ‚æµ
      }

      // è§„èŒƒè·¯å¾„å¹¶åŠ è½½èµ„æºå­—èŠ‚
      String normalizedPath = assetPath.trim();
      normalizedPath = normalizedPath.replaceAll('/ ', '/').replaceAll(' /', '/');
      if (!normalizedPath.startsWith('assets/')) {
        normalizedPath = 'assets/$normalizedPath';
      }

      ByteData bd;
      try {
        bd = await rootBundle.load(normalizedPath);
      } catch (_) {
        // å›é€€åˆ°é»˜è®¤èµ„æº
        bd = await rootBundle.load('assets/audio/ringtones/test.wav');
        normalizedPath = 'assets/audio/ringtones/test.wav';
      }

      final bytes = bd.buffer.asUint8List();
      final contentType = normalizedPath.toLowerCase().endsWith('.wav')
          ? 'audio/wav'
          : normalizedPath.toLowerCase().endsWith('.mp3')
              ? 'audio/mpeg'
              : 'application/octet-stream';

      final source = _buildInMemoryAudioSource(bytes, contentType: contentType);

      await _sfxPlayer.stop();
      await _sfxPlayer.setVolume(volume.clamp(0.0, 1.0));
      await _sfxPlayer.setAudioSource(source);
      await _sfxPlayer.play();

      _lastSfxAt = DateTime.now();
    } catch (e) {
      debugPrint('âš ï¸ æ’­æ”¾UIéŸ³æ•ˆå¤±è´¥: $e');
    }
  }

  Future<void> playAudioFromAsset(String assetPath) async {
    await _playerLock.synchronized(() async {
      await _withPlaybackMode(() async {
        try {
          await _player.stop();

          // å…ˆåœæ­¢åå°ä¿æ´»
          if (_keepAlive) {
            await stopBackgroundKeepAlive();
          }

          await _player.setVolume(1.0);
          debugPrint('ğŸ”Š éŸ³é‡å·²è®¾ç½®ä¸º: 1.0');

          // æ ‡å‡†åŒ–èµ„æºè·¯å¾„ï¼šå»é™¤å¤šä½™ç©ºç™½ã€ä¿®æ­£æ–œæ ä¸¤ä¾§çš„ç©ºæ ¼ï¼Œå¹¶ç¡®ä¿ä»¥ 'assets/' å¼€å¤´
          String normalizedPath = assetPath.trim();
          normalizedPath = normalizedPath
              .replaceAll('/ ', '/')
              .replaceAll(' /', '/');
          if (!normalizedPath.startsWith('assets/')) {
            normalizedPath = 'assets/$normalizedPath';
          }

          // éªŒè¯èµ„æºæ˜¯å¦å­˜åœ¨
          try {
            await rootBundle.load(normalizedPath);
            debugPrint('âœ… èµ„æºæ–‡ä»¶éªŒè¯æˆåŠŸ: $normalizedPath');
          } catch (e) {
            debugPrint('âš ï¸ èµ„æºä¸å­˜åœ¨ï¼Œå›é€€åˆ°é»˜è®¤é“ƒå£°: $e');
            normalizedPath = 'assets/audio/ringtones/ringring.wav';
            try {
              await rootBundle.load(normalizedPath);
              debugPrint('âœ… é»˜è®¤é“ƒå£°éªŒè¯æˆåŠŸ: $normalizedPath');
            } catch (e2) {
              debugPrint('âŒ è¿é»˜è®¤é“ƒå£°éƒ½ä¸å­˜åœ¨: $e2');
              throw Exception('éŸ³é¢‘èµ„æºæ–‡ä»¶ä¸å­˜åœ¨: $assetPathï¼Œä¸”é»˜è®¤é“ƒå£°ä¹Ÿä¸å¯ç”¨');
            }
          }

          debugPrint('ğŸ“ èµ„æºè·¯å¾„: $normalizedPath');

          // ç›´æ¥æ”¹ä¸ºä»¥å†…å­˜æµæ’­æ”¾ï¼Œé¿å…èµ„äº§é”®å·®å¼‚å¯¼è‡´çš„é—®é¢˜
          final bd = await rootBundle.load(normalizedPath);
          final bytes = bd.buffer.asUint8List();
          if (normalizedPath.toLowerCase().endsWith('.wav')) {
            debugPrint('ğŸ” èµ„äº§WAVå¤´ä¿¡æ¯:');
            WavValidator.printWavHeader(bytes);
            final ok = WavValidator.validateWav(bytes);
            final has = WavValidator.hasValidSamples(bytes);
            debugPrint(
              'WAVæ ¡éªŒ => valid: $ok, hasData: $has, size: ${bytes.length}',
            );
          }
          final ext = normalizedPath.toLowerCase().endsWith('.wav')
              ? 'audio/wav'
              : normalizedPath.toLowerCase().endsWith('.mp3')
              ? 'audio/mpeg'
              : 'application/octet-stream';
          final source = _buildInMemoryAudioSource(bytes, contentType: ext);
          await _player.setAudioSource(source);
          debugPrint('âœ… éŸ³é¢‘æºè®¾ç½®å®Œæˆ(å†…å­˜)');

          _isPlaying = true;
          _player.play();
          debugPrint('â–¶ï¸ å¼€å§‹æ’­æ”¾èµ„æº: $assetPath');

          await _playerStateSub?.cancel();
          _playerStateSub = _player.playerStateStream.listen((state) {
            debugPrint('ğŸµ æ’­æ”¾çŠ¶æ€: ${state.processingState}');
            if (state.processingState == ProcessingState.completed) {
              _isPlaying = false;
              debugPrint('âœ… éŸ³é¢‘æ’­æ”¾å®Œæˆ');
            }
          });
        } catch (e, stack) {
          debugPrint('âŒ æ’­æ”¾èµ„æºå¤±è´¥: $e');
          debugPrint('$stack');
          _isPlaying = false;
          rethrow;
        }
      });
    });
  }

  Future<void> playAudioFromUrl(String url) async {
    await _playerLock.synchronized(() async {
      await _withPlaybackMode(() async {
        try {
          await _player.stop();

          if (_keepAlive) {
            await stopBackgroundKeepAlive();
          }

          await _player.setVolume(1.0);
          debugPrint('ğŸ”Š éŸ³é‡å·²è®¾ç½®ä¸º: 1.0');

          await _player.setUrl(url);
          _isPlaying = true;

          _player.play();
          debugPrint('â–¶ï¸ å¼€å§‹æ’­æ”¾URL: $url');

          await _playerStateSub?.cancel();
          _playerStateSub = _player.playerStateStream.listen((state) {
            debugPrint('ğŸµ æ’­æ”¾çŠ¶æ€: ${state.processingState}');
            if (state.processingState == ProcessingState.completed) {
              _isPlaying = false;
              debugPrint('âœ… éŸ³é¢‘æ’­æ”¾å®Œæˆ');
            }
          });
        } catch (e) {
          debugPrint('âŒ æ’­æ”¾URLå¤±è´¥: $e');
          _isPlaying = false;
        }
      });
    });
  }

  Future<void> stopPlaying() async {
    try {
      await _player.stop();
      _isPlaying = false;
      debugPrint('åœæ­¢æ’­æ”¾');
    } catch (e) {
      debugPrint('åœæ­¢æ’­æ”¾å¤±è´¥: $e');
    }
  }

  Future<void> pausePlaying() async {
    try {
      await _player.pause();
      debugPrint('æš‚åœæ’­æ”¾');
    } catch (e) {
      debugPrint('æš‚åœæ’­æ”¾å¤±è´¥: $e');
    }
  }

  Future<void> resumePlaying() async {
    try {
      await _player.play();
      debugPrint('ç»§ç»­æ’­æ”¾');
    } catch (e) {
      debugPrint('ç»§ç»­æ’­æ”¾å¤±è´¥: $e');
    }
  }

  Future<void> enterVoiceChatMode() async {
    try {
      await _configureVoiceChatSession();
      debugPrint('ğŸ™ï¸ åˆ‡æ¢è‡³è¯­éŸ³èŠå¤©æ¨¡å¼');
    } catch (e) {
      debugPrint('âŒ åˆ‡æ¢è¯­éŸ³èŠå¤©æ¨¡å¼å¤±è´¥: $e');
    }
  }

  Future<void> ensureVoiceChatMode() async {
    if (isVoiceChatMode) return;
    await enterVoiceChatMode();
  }

  Future<void> exitVoiceChatMode() async {
    // ä¿®å¤ï¼šä¸åœ¨è¿™é‡Œæ‰“å°æ—¥å¿—ï¼Œé¿å…é‡å¤ï¼Œ_configurePlaybackSession å·²æœ‰æ—¥å¿—
    await _configurePlaybackSession();
  }

  /// ç®€å•çš„éŸ³é¢‘æµ‹è¯•ï¼šä½¿ç”¨ PCMStreamService æ’­æ”¾æµ‹è¯•éŸ³
  Future<void> testAudioPlayback() async {
    try {
      debugPrint('ğŸµ å¼€å§‹éŸ³é¢‘æ’­æ”¾æµ‹è¯•...');

      // ä¿®å¤ï¼šä¸å†åˆ‡æ¢æ¨¡å¼ï¼Œç›´æ¥ä½¿ç”¨ PCMStreamService æ’­æ”¾
      // è¿™æ ·ä¸ä¼šå¹²æ‰°å½“å‰çš„å½•éŸ³ä¼šè¯

      // ç”Ÿæˆä¸€ä¸ªç®€å•çš„ 440Hz æ­£å¼¦æ³¢ä¿¡å·ï¼ˆA4 éŸ³ï¼‰
      const sampleRate = 16000;
      const duration = 0.5; // 0.5 ç§’
      const frequency = 440.0; // A4 éŸ³

      final samples = <int>[];
      for (int i = 0; i < (sampleRate * duration).toInt(); i++) {
        final t = i / sampleRate;
        final sample = (32767 * 0.3 * sin(2 * 3.14159 * frequency * t)).round();
        samples.add(sample & 0xFF); // Low byte
        samples.add((sample >> 8) & 0xFF); // High byte
      }

      // æ„é€  WAV æ–‡ä»¶å¤´
      final dataSize = samples.length;
      final fileSize = 36 + dataSize;

      final wavData = <int>[
        // "RIFF" header
        0x52, 0x49, 0x46, 0x46,
        fileSize & 0xFF,
        (fileSize >> 8) & 0xFF,
        (fileSize >> 16) & 0xFF,
        (fileSize >> 24) & 0xFF,
        // "WAVE" format
        0x57, 0x41, 0x56, 0x45,
        // "fmt " subchunk
        0x66, 0x6D, 0x74, 0x20,
        16, 0, 0, 0, // Subchunk1Size
        1, 0, // AudioFormat (PCM)
        1, 0, // NumChannels (mono)
        sampleRate & 0xFF, (sampleRate >> 8) & 0xFF, 0, 0, // SampleRate
        (sampleRate * 2) & 0xFF,
        ((sampleRate * 2) >> 8) & 0xFF,
        0,
        0, // ByteRate
        2, 0, // BlockAlign
        16, 0, // BitsPerSample
        // "data" subchunk
        0x64, 0x61, 0x74, 0x61,
        dataSize & 0xFF,
        (dataSize >> 8) & 0xFF,
        (dataSize >> 16) & 0xFF,
        (dataSize >> 24) & 0xFF,
        ...samples,
      ];

      // ä½¿ç”¨ PCMStreamService ç›´æ¥æ’­æ”¾ PCM æ•°æ®
      final pcmData = Uint8List.fromList(samples);
      
      // åˆå§‹åŒ– PCMStreamService
      if (!PCMStreamService.instance.isInitialized) {
        await PCMStreamService.instance.initialize();
      }
      
      // å–‚å…¥ PCM æ•°æ®
      await PCMStreamService.instance.feedPCM(pcmData);
      
      debugPrint('âœ… æµ‹è¯•éŸ³é¢‘å·²å‘é€åˆ° PCMStreamService');
      
      // ç­‰å¾… 1 ç§’ååœæ­¢
      await Future.delayed(const Duration(seconds: 1));
      await PCMStreamService.instance.stopStreaming();
    } catch (e, stackTrace) {
      debugPrint('âŒ éŸ³é¢‘æ’­æ”¾æµ‹è¯•å¤±è´¥: $e');
      debugPrint('ğŸ“ å †æ ˆ: $stackTrace');
    }
  }

  void dispose() {
    _recorder.dispose();
    _player.dispose();
    _audioStreamController?.close();
  }

  List<int> _createMinimalAudioData() {
    // åˆ›å»ºä¸€ä¸ªæœ€å°çš„WAVæ–‡ä»¶å¤´ + 1ç§’çš„é™éŸ³æ•°æ®
    const sampleRate = 8000; // ä½é‡‡æ ·ç‡
    const duration = 1; // 1ç§’
    const numSamples = sampleRate * duration;
    final samples = List<int>.filled(numSamples * 2, 0); // 16-bité™éŸ³

    // WAVæ–‡ä»¶å¤´
    final dataSize = samples.length;
    final fileSize = 36 + dataSize;

    return [
      // "RIFF"
      0x52, 0x49, 0x46, 0x46,
      // æ–‡ä»¶å¤§å° - 8
      fileSize & 0xFF,
      (fileSize >> 8) & 0xFF,
      (fileSize >> 16) & 0xFF,
      (fileSize >> 24) & 0xFF,
      // "WAVE"
      0x57, 0x41, 0x56, 0x45,
      // "fmt "
      0x66, 0x6D, 0x74, 0x20,
      // fmt chunk size (16)
      0x10, 0x00, 0x00, 0x00,
      // Audio format (1 = PCM)
      0x01, 0x00,
      // å£°é“æ•° (1 = å•å£°é“)
      0x01, 0x00,
      // é‡‡æ ·ç‡
      sampleRate & 0xFF,
      (sampleRate >> 8) & 0xFF,
      0x00, 0x00,
      // å­—èŠ‚ç‡ (sampleRate * channels * bitsPerSample/8)
      (sampleRate * 2) & 0xFF, ((sampleRate * 2) >> 8) & 0xFF,
      0x00, 0x00,
      // Block align (channels * bitsPerSample/8)
      0x02, 0x00,
      // Bits per sample
      0x10, 0x00,
      // "data"
      0x64, 0x61, 0x74, 0x61,
      // Data size
      dataSize & 0xFF,
      (dataSize >> 8) & 0xFF,
      (dataSize >> 16) & 0xFF,
      (dataSize >> 24) & 0xFF,
      // é™éŸ³æ ·æœ¬æ•°æ®
      ...samples,
    ];
  }
}

class _BytesAudioSource extends StreamAudioSource {
  _BytesAudioSource(this.bytes, {required this.contentType});

  final Uint8List bytes;
  final String contentType;

  @override
  Future<StreamAudioResponse> request([int? start, int? end]) async {
    final totalLength = bytes.length;
    final actualStart = (start ?? 0).clamp(0, totalLength);
    final clampedEnd = end == null ? totalLength : end.clamp(0, totalLength);
    final actualEnd = clampedEnd < actualStart ? actualStart : clampedEnd;
    final slice = bytes.sublist(actualStart, actualEnd);
    return StreamAudioResponse(
      sourceLength: bytes.length,
      contentLength: slice.length,
      offset: actualStart,
      stream: Stream.value(slice),
      contentType: contentType,
    );
  }
}
